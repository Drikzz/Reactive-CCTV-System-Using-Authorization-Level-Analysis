# ğŸ¯ Behavior Recognition Inference Guide

Real-time behavior classification with person tracking using YOLOv8 + LSTM.

## ğŸŒŸ Features

âœ… **Multi-Person Tracking** - Track and classify multiple people simultaneously  
âœ… **Real-time Processing** - Smooth inference on webcam or video files  
âœ… **Temporal Windowing** - Uses 60-frame sequences for accurate classification  
âœ… **Prediction Smoothing** - Majority voting over 5 predictions for stability  
âœ… **Visual Feedback** - Skeleton overlay, bounding boxes, and behavior labels  
âœ… **Auto Cleanup** - Removes inactive tracks automatically  

---

## ğŸ“‹ Prerequisites

Before running inference, ensure you have:

1. **Trained LSTM Model**
   - Location: `models/lstm_mn/best_model.pth`
   - Train using: `python run_training.py`

2. **YOLOv8-Pose Model**
   - Location: `models/YOLOv8/yolov8m-pose.pt`
   - Should already be downloaded

3. **Required Libraries**
   ```powershell
   pip install ultralytics opencv-python torch tqdm
   ```

---

## ğŸš€ Usage

### 1. Webcam Inference (Default)

```powershell
cd behavior_recognition
python run_inference.py --webcam
```

**Controls:**
- Press `q` to quit
- Press `s` to save screenshot

### 2. Webcam with Specific Camera

```powershell
# Use camera 0 (default)
python run_inference.py --webcam --camera-id 0

# Use camera 1 (external webcam)
python run_inference.py --webcam --camera-id 1
```

### 3. Video File Inference

```powershell
# Process and display
python run_inference.py --video path/to/video.mp4

# Process and save output
python run_inference.py --video input.mp4 --output runs/inference/output.mp4
```

### 4. CPU Mode (No GPU)

```powershell
python run_inference.py --webcam --device cpu
```

---

## âš™ï¸ Command-Line Arguments

| Argument | Description | Default |
|----------|-------------|---------|
| `--webcam` | Use webcam as input source | - |
| `--video` | Path to input video file | - |
| `--camera-id` | Camera device ID (0, 1, 2...) | 0 |
| `--output` | Path to save output video | None |
| `--model` | Path to LSTM model | `models/lstm_mn/best_model.pth` |
| `--pose-model` | Path to YOLOv8-pose | `models/YOLOv8/yolov8m-pose.pt` |
| `--device` | Device to use (`cuda` or `cpu`) | `cuda` |

---

## ğŸ“Š How It Works

### 1. **Person Detection & Tracking**
```
Frame â†’ YOLOv8-pose â†’ Detect persons â†’ Track IDs
                    â†“
              Extract 17 keypoints per person
```

### 2. **Temporal Windowing**
```
Person ID: 1
â”œâ”€â”€ Frame 1: [17x2 keypoints]
â”œâ”€â”€ Frame 2: [17x2 keypoints]
â”œâ”€â”€ ...
â””â”€â”€ Frame 60: [17x2 keypoints] â†’ Ready for classification!
```

### 3. **Behavior Classification**
```
Sequence [60, 17, 2] â†’ Flatten â†’ [60, 34]
                                    â†“
                              LSTM Classifier
                                    â†“
                          Predicted Behavior + Confidence
```

### 4. **Prediction Smoothing**
```
Last 5 predictions: [0, 0, 1, 0, 0]
Majority vote: 0 (assault-fighting)
Display: "assault-fighting (0.92)"
```

---

## ğŸ¨ Visualization

The inference displays:

1. **Bounding Boxes** - Color-coded per person
2. **Person ID** - Unique tracking ID
3. **Pose Skeleton** - 17 COCO keypoints connected
4. **Behavior Label** - Current predicted behavior
5. **Confidence** - Prediction confidence percentage
6. **Statistics Panel**:
   - FPS (Frames Per Second)
   - Tracked Persons count
   - Sequence window size

---

## ğŸ“ˆ Performance Tips

### For Better FPS:

1. **Use GPU** (CUDA)
   ```powershell
   python run_inference.py --webcam --device cuda
   ```

2. **Lower Resolution**
   - Webcam auto-set to 1280x720
   - Modify in code if needed

3. **Reduce Sequence Length**
   - Edit `config.py`: `FIXED_SEQUENCE_LENGTH = 30` (faster but less accurate)

### For Better Accuracy:

1. **Increase Smoothing Window**
   - Modify `smoothing_window=5` to `smoothing_window=10` in `inference_behavior.py`

2. **Longer Sequences**
   - Keep `FIXED_SEQUENCE_LENGTH = 60` or increase to 100

---

## ğŸ› ï¸ Troubleshooting

### Issue: "LSTM model not found"
**Solution:**
```powershell
# Train the model first
python run_training.py
```

### Issue: "Cannot open camera"
**Solution:**
```powershell
# Try different camera IDs
python run_inference.py --webcam --camera-id 1
python run_inference.py --webcam --camera-id 2
```

### Issue: Low FPS
**Solutions:**
1. Use GPU: `--device cuda`
2. Lower confidence threshold in `config.py`
3. Reduce sequence length

### Issue: Flickering predictions
**Solution:**
- Increase smoothing window in `PersonTracker.__init__(smoothing_window=10)`

---

## ğŸ’¡ Examples

### Example 1: Monitor Security Camera
```powershell
# Use external USB camera with output saving
python run_inference.py --webcam --camera-id 1 --output security_footage.mp4
```

### Example 2: Analyze Existing Footage
```powershell
# Process CCTV recording
python run_inference.py --video cctv_recording.mp4 --output analyzed_output.mp4
```

### Example 3: Quick Test on Laptop
```powershell
# Use built-in webcam with CPU
python run_inference.py --webcam --device cpu
```

---

## ğŸ“ Output Structure

When saving output:
```
runs/
â””â”€â”€ inference/
    â”œâ”€â”€ output.mp4          # Annotated video
    â””â”€â”€ screenshot_0000.jpg # Screenshots (press 's')
```

---

## ğŸ¯ Expected Results

**Display shows:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FPS: 28.5                         â”‚
â”‚ Tracked Persons: 2                â”‚
â”‚ Window: 60 frames                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Person 1: [Bounding Box]
â”œâ”€â”€ ID: 1 | stealing (87.3%)
â””â”€â”€ [Skeleton overlay]

Person 2: [Bounding Box]
â”œâ”€â”€ ID: 2 | Collecting...
â””â”€â”€ [Skeleton overlay]
```

---

## ğŸš€ Quick Start Checklist

- [ ] Train LSTM model (`python run_training.py`)
- [ ] Verify model exists (`models/lstm_mn/best_model.pth`)
- [ ] Connect webcam or prepare video file
- [ ] Run inference (`python run_inference.py --webcam`)
- [ ] Press `q` to quit, `s` to screenshot

---

## ğŸ“ Support

**Common Issues:**
- Model not found â†’ Train first
- No camera â†’ Check `--camera-id`
- Low FPS â†’ Use `--device cuda`
- Unstable predictions â†’ Increase smoothing

**File Locations:**
- Inference script: `behavior_recognition/inference_behavior.py`
- Launcher: `behavior_recognition/run_inference.py`
- Config: `behavior_recognition/config.py`

---

## âœ¨ Features Summary

| Feature | Description |
|---------|-------------|
| **Multi-Person** | Track and classify multiple people |
| **Real-time** | 25-30 FPS on GPU |
| **Temporal** | 60-frame sequence window |
| **Smoothing** | 5-frame majority voting |
| **Auto-cleanup** | Remove inactive tracks |
| **Visualization** | Skeletons + boxes + labels |
| **Flexible Input** | Webcam or video file |
| **Save Output** | Optional video saving |

Ready to classify behaviors in real-time! ğŸ‰
